{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_counts = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "mimic_benchmark_dir = Path('/scratch/gobi2/haoran/shared_data/MIMIC_benchmarks/') # update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduced from https://github.com/YerevaNN/mimic3-benchmarks/blob/master/mimic3benchmark/readers.py\n",
    "class Reader(object):\n",
    "    def __init__(self, dataset_dir, listfile=None):\n",
    "        self._dataset_dir = dataset_dir\n",
    "        self._current_index = 0 \n",
    "        if listfile is None:\n",
    "            listfile_path = os.path.join(dataset_dir, \"listfile.csv\")\n",
    "        else:\n",
    "            listfile_path = listfile\n",
    "        with open(listfile_path, \"r\") as lfile:\n",
    "            self._data = lfile.readlines()\n",
    "        self._listfile_header = self._data[0]\n",
    "        self._data = self._data[1:]\n",
    "\n",
    "    def get_number_of_examples(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def random_shuffle(self, seed=None):\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        random.shuffle(self._data)\n",
    "\n",
    "    def read_example(self, index):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def read_next(self):\n",
    "        to_read_index = self._current_index\n",
    "        self._current_index += 1\n",
    "        if self._current_index == self.get_number_of_examples():\n",
    "            self._current_index = 0 \n",
    "        return self.read_example(to_read_index)\n",
    "    \n",
    "class InHospitalMortalityReader(Reader):\n",
    "    def __init__(self, dataset_dir, listfile=None, period_length=48.0):\n",
    "        \"\"\" Reader for in-hospital moratality prediction task.\n",
    "\n",
    "        :param dataset_dir:   Directory where timeseries files are stored.\n",
    "        :param listfile:      Path to a listfile. If this parameter is left `None` then\n",
    "                              `dataset_dir/listfile.csv` will be used.\n",
    "        :param period_length: Length of the period (in hours) from which the prediction is done.\n",
    "        \"\"\"\n",
    "        Reader.__init__(self, dataset_dir, listfile)\n",
    "        self._data = [line.split(',') for line in self._data]\n",
    "        self._data = [(x, int(y)) for (x, y) in self._data]\n",
    "        self._period_length = period_length\n",
    "\n",
    "    def _read_timeseries(self, ts_filename):\n",
    "        ret = []\n",
    "        with open(os.path.join(self._dataset_dir, ts_filename), \"r\") as tsfile:\n",
    "            header = tsfile.readline().strip().split(',')\n",
    "            assert header[0] == \"Hours\"\n",
    "            for line in tsfile:\n",
    "                mas = line.strip().split(',')\n",
    "                ret.append(np.array(mas))\n",
    "        return (np.stack(ret), header)\n",
    "\n",
    "    def read_example(self, index):\n",
    "        \"\"\" Reads the example with given index.\n",
    "\n",
    "        :param index: Index of the line of the listfile to read (counting starts from 0).\n",
    "        :return: Dictionary with the following keys:\n",
    "            X : np.array\n",
    "                2D array containing all events. Each row corresponds to a moment.\n",
    "                First column is the time and other columns correspond to different\n",
    "                variables.\n",
    "            t : float\n",
    "                Length of the data in hours. Note, in general, it is not equal to the\n",
    "                timestamp of last event.\n",
    "            y : int (0 or 1)\n",
    "                In-hospital mortality.\n",
    "            header : array of strings\n",
    "                Names of the columns. The ordering of the columns is always the same.\n",
    "            name: Name of the sample.\n",
    "        \"\"\"\n",
    "        if index < 0 or index >= len(self._data):\n",
    "            raise ValueError(\"Index must be from 0 (inclusive) to number of lines (exclusive).\")\n",
    "\n",
    "        name = self._data[index][0]\n",
    "        t = self._period_length\n",
    "        y = self._data[index][1]\n",
    "        (X, header) = self._read_timeseries(name)\n",
    "\n",
    "        return {\"X\": X,\n",
    "                \"t\": t,\n",
    "                \"y\": y,\n",
    "                \"header\": header,\n",
    "                \"name\": name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reader = InHospitalMortalityReader(dataset_dir=mimic_benchmark_dir/'in-hospital-mortality' / 'train')\n",
    "test_reader = InHospitalMortalityReader(dataset_dir=mimic_benchmark_dir/'in-hospital-mortality' / 'test')\n",
    "all_stays = pd.read_csv(os.path.join(mimic_benchmark_dir, 'root/', 'all_stays.csv'), parse_dates = ['INTIME']).set_index('ICUSTAY_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bins = [0, 12, 24, 36, 48]\n",
    "\n",
    "features = [\n",
    "#     'Hours',\n",
    "#  'Capillary refill rate',\n",
    " 'Diastolic blood pressure',\n",
    "    'Fraction inspired oxygen',\n",
    "#  'Glascow coma scale eye opening',\n",
    "#  'Glascow coma scale motor response',\n",
    " 'Glascow coma scale total',\n",
    "#  'Glascow coma scale verbal response',\n",
    " 'Glucose',\n",
    " 'Heart Rate',\n",
    " # 'Height',\n",
    " 'Mean blood pressure',\n",
    " 'Oxygen saturation',\n",
    " 'Respiratory rate',\n",
    " 'Systolic blood pressure',\n",
    " 'Temperature',\n",
    " 'Weight',\n",
    " 'pH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_eth(string):\n",
    "    string = string.lower()\n",
    "    if bool(re.search('^white', string)):\n",
    "        return \"white\"\n",
    "    elif bool(re.search('^black', string)):\n",
    "        return \"black\"\n",
    "    else:\n",
    "        return \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "meta = {}\n",
    "for fold in ['train', 'test']:\n",
    "    reader = train_reader if fold =='train' else test_reader\n",
    "    for count, i in enumerate(tqdm(range(reader.get_number_of_examples()))):\n",
    "        ex = reader.read_example(i)\n",
    "        df = pd.DataFrame(ex['X'], columns = ex['header'])[['Hours'] + features]\n",
    "        df = df.replace('', np.nan).astype(np.float32).sort_values(by = 'Hours', ascending = True)\n",
    "        df = df[df.Hours < ex['t']]\n",
    "        ind = np.digitize(df['Hours'], time_bins)\n",
    "        df = df.groupby(ind).agg(['mean', 'count'])\n",
    "        df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
    "        df = df.drop(columns = ['Hours mean', \"Hours count\"])  \n",
    "        # df = df.reset_index().rename(columns = {'index': 't'})\n",
    "        extra = {'target': ex['y']} \n",
    "        \n",
    "        subj_id = int(ex['name'].split('_')[0])\n",
    "        stay = pd.read_csv(os.path.join(mimic_benchmark_dir, 'root', fold, str(subj_id), ex['name'].split('_')[1]+'.csv')).iloc[0]\n",
    "        extra['Gender'] = 'M' if int(stay['Gender']) == 2 else 'F'\n",
    "        extra['Age'] = float(stay['Age'])\n",
    "        extra['fold_id'] = fold\n",
    "        extra['Race'] = map_eth(all_stays.loc[stay.Icustay, 'ETHNICITY'])\n",
    "        pid = ex['name'][:-4]\n",
    "        meta[pid] = extra\n",
    "        data[pid] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(data)\n",
    "df.index.rename(['id', 't'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.DataFrame.from_dict(meta, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterables = [np.unique(df.index.get_level_values(0).tolist()), list(range(1, len(time_bins)))]\n",
    "multiind = pd.MultiIndex.from_product(iterables, names = ['id', 't'])\n",
    "ind_df = pd.DataFrame(index = multiind)\n",
    "df = pd.merge(ind_df, df, left_index = True, right_index = True, how = 'left').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if i.endswith('count'):\n",
    "        df[i] = df[i].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes values for imputation on training set\n",
    "df2 = df.copy()\n",
    "df2 = df2.reset_index().pivot_table(index = 'id', columns = 't')\n",
    "df2.columns = ['_'.join(map(str, reversed(col))).strip() for col in df2.columns.values]\n",
    "df2 = pd.merge(df2, meta_df, left_index = True, right_index = True, how = 'inner')\n",
    "\n",
    "_, val_ids = train_test_split(df2[df2.fold_id == 'train'].index, test_size = 0.25, \n",
    "                              random_state = 42, stratify = df2.loc[df2.fold_id == 'train','Race'])\n",
    "df2.loc[val_ids, 'fold_id'] = 'eval'\n",
    "\n",
    "train_ids = list(df2[df2.fold_id == 'train'].index)\n",
    "impute_vals = df.loc[train_ids].reset_index().groupby('t').apply(lambda x: {i: x[i].mean() for i in x if i.endswith('mean')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_func(series):\n",
    "    for ind, i in series.iteritems():\n",
    "        if pd.isnull(i):\n",
    "            series[ind] = impute_vals[ind[1]][series.name]\n",
    "            \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('id').ffill()\n",
    "df = df.groupby('id').transform(impute_func)\n",
    "df = df.reset_index().pivot_table(index = 'id', columns = 't')\n",
    "df.columns = ['_'.join(map(str, reversed(col))).strip() for col in df.columns.values]\n",
    "df = pd.merge(df, meta_df, left_index = True, right_index = True, how = 'inner')\n",
    "df.loc[val_ids, 'fold_id'] = 'eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_counts:\n",
    "    cols_to_drop = []\n",
    "    for i in df.columns:\n",
    "        if i.endswith('count'):\n",
    "            cols_to_drop.append(i)\n",
    "    df = df.drop(columns = cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename_axis('ID').reset_index().to_csv('./mimic_mortality_tabular.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
